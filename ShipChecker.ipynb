{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShipChecker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## raw data path\n",
    "rawDataPath = './portData/rawData.txt'\n",
    "\n",
    "## google search api path\n",
    "googleSearchApiPath = '../googleSearchApi.txt'\n",
    "## google search custom search engine id\n",
    "googleSearchCseIdPath = '../googleSearchCSE.txt'\n",
    "\n",
    "#Processingdata path\n",
    "processingDataPath = './processingData.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "from pyppeteer import launch\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=(SettingWithCopyWarning))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE &amp; TIME</th>\n",
       "      <th>ARRIVAL / DEPARTURE</th>\n",
       "      <th>VESSEL</th>\n",
       "      <th>VESSEL TYPE</th>\n",
       "      <th>FROM</th>\n",
       "      <th>TO</th>\n",
       "      <th>IN PORT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed 20 Mar 20:00</td>\n",
       "      <td>ARRIVAL</td>\n",
       "      <td>KOTA LIMA</td>\n",
       "      <td>CONTAINER SHIP (FULLY CELLULAR)</td>\n",
       "      <td>CHIWAN PT</td>\n",
       "      <td>12 BROTHERSON DOCK (BD12)</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed 20 Mar 22:00</td>\n",
       "      <td>ARRIVAL</td>\n",
       "      <td>MSC KANU F</td>\n",
       "      <td>CONTAINER SHIP (FULLY CELLULAR)</td>\n",
       "      <td>BELL BAY</td>\n",
       "      <td>9 BROTHERSON DOCK (BD9)</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thu 21 Mar 03:00</td>\n",
       "      <td>ARRIVAL</td>\n",
       "      <td>WIDE INDIA</td>\n",
       "      <td>CONTAINER SHIP (FULLY CELLULAR)</td>\n",
       "      <td>AUCKLAND</td>\n",
       "      <td>7 BROTHERSON DOCK (BD7)</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thu 21 Mar 15:00</td>\n",
       "      <td>ARRIVAL</td>\n",
       "      <td>GASCHEM HOMER</td>\n",
       "      <td>LPG TANKER</td>\n",
       "      <td>BRISBANE</td>\n",
       "      <td>BULK LIQUID BERTH 1 (BLB1)</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thu 21 Mar 17:00</td>\n",
       "      <td>ARRIVAL</td>\n",
       "      <td>MARI COUVA</td>\n",
       "      <td>CHEMICAL/PRODUCTS TANKER</td>\n",
       "      <td>ONSAN/ULSAN</td>\n",
       "      <td>BULK LIQUID BERTH 1 (BLB1)</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE & TIME ARRIVAL / DEPARTURE         VESSEL  \\\n",
       "0  Wed 20 Mar 20:00             ARRIVAL      KOTA LIMA   \n",
       "1  Wed 20 Mar 22:00             ARRIVAL     MSC KANU F   \n",
       "2  Thu 21 Mar 03:00             ARRIVAL     WIDE INDIA   \n",
       "3  Thu 21 Mar 15:00             ARRIVAL  GASCHEM HOMER   \n",
       "4  Thu 21 Mar 17:00             ARRIVAL     MARI COUVA   \n",
       "\n",
       "                       VESSEL TYPE         FROM                          TO  \\\n",
       "0  CONTAINER SHIP (FULLY CELLULAR)    CHIWAN PT   12 BROTHERSON DOCK (BD12)   \n",
       "1  CONTAINER SHIP (FULLY CELLULAR)     BELL BAY     9 BROTHERSON DOCK (BD9)   \n",
       "2  CONTAINER SHIP (FULLY CELLULAR)     AUCKLAND     7 BROTHERSON DOCK (BD7)   \n",
       "3                       LPG TANKER     BRISBANE  BULK LIQUID BERTH 1 (BLB1)   \n",
       "4         CHEMICAL/PRODUCTS TANKER  ONSAN/ULSAN  BULK LIQUID BERTH 1 (BLB1)   \n",
       "\n",
       "  IN PORT  \n",
       "0      NO  \n",
       "1      NO  \n",
       "2      NO  \n",
       "3      NO  \n",
       "4      NO  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load raw data and show the first 5 rows\n",
    "rawData = pd.read_csv(rawDataPath, sep='\\t')\n",
    "rawData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaS\n",
      "e0f84b16165d14dc2\n"
     ]
    }
   ],
   "source": [
    "# load google search api key and custom search engine id\n",
    "googleApiKey = open(googleSearchApiPath, 'r').read()\n",
    "print(googleApiKey[:5])\n",
    "googleSearchCseId = open(googleSearchCseIdPath, 'r').read()\n",
    "print(googleSearchCseId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html><html lang=\"en\"><head><script type=\"text/javascript\" async=\"\" src=\"https://static.criteo.net/js/ld/publishertag.prebid.117.js\"></script>\n",
      "<script type=\"text/javascript\" async=\"\" src=\"https://static.vesselfinder.net/web/tippy-all.2.min.js\"></script><script async=\"\" type=\"text/javascript\" src=\"https://btloader.com/tag?o=5708166709903360&amp;upapi=true\"></script><script async=\"\" type=\"text/javascript\" src=\"https://cmp.inmobi.com/tcfv2/cmp2.js?referer=www.vesselfinder.com\"></script><script async=\"\" type=\"text/javascript\" src=\"https://securepubads.g.doubleclick.net/tag/js/gpt.js\"></script><script async=\"\" src=\"//c.amazon-adsystem.com/aax2/apstag.js\"></script><script async=\"\" type=\"text/javascript\" src=\"https://cdn.fuseplatform.net/prebid/prebid-baa15e73388ad0f63a21b359ac193c86.js\"></script><script async=\"\" type=\"text/javascript\" src=\"https://cmp.inmobi.com/choice/PRrmquD1Ggcb1/www.vesselfinder.com/choice.js?tag_version=V3\"></script><script async=\"\" src=\"https://cdn.fuseplatfor\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_vessel_details' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m processingData \u001b[38;5;241m=\u001b[39m rawData\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m processingData[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnippet\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimo_number\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mprocessingData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_vessel_details\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVESSEL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexpand\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m processingData\u001b[38;5;241m.\u001b[39mto_csv(processingDataPath)\n",
      "File \u001b[1;32mh:\\anaconda\\envs\\NormalPorjectwithoutAI\\lib\\site-packages\\pandas\\core\\frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9414\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9416\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9421\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9422\u001b[0m )\n\u001b[1;32m-> 9423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mh:\\anaconda\\envs\\NormalPorjectwithoutAI\\lib\\site-packages\\pandas\\core\\apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mh:\\anaconda\\envs\\NormalPorjectwithoutAI\\lib\\site-packages\\pandas\\core\\apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mh:\\anaconda\\envs\\NormalPorjectwithoutAI\\lib\\site-packages\\pandas\\core\\apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      1\u001b[0m processingData \u001b[38;5;241m=\u001b[39m rawData\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m processingData[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnippet\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimo_number\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m processingData\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mget_vessel_details\u001b[49m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVESSEL\u001b[39m\u001b[38;5;124m'\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, result_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpand\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m processingData\u001b[38;5;241m.\u001b[39mto_csv(processingDataPath)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_vessel_details' is not defined"
     ]
    }
   ],
   "source": [
    "processingData = rawData.head(1)\n",
    "\n",
    "processingData[['link','snippet','imo_number']] = processingData.apply(lambda row: get_vessel_details(row['VESSEL']), axis=1, result_type='expand')\n",
    "\n",
    "processingData.to_csv(processingDataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nest_asyncio.apply()  # 应用nest_asyncio\n",
    "\n",
    "async def scrape(url):\n",
    "    browser = await launch(headless=True, args=['--no-sandbox'])\n",
    "    page = await browser.newPage()\n",
    "    await page.setUserAgent('My User Agent')\n",
    "    await page.goto(url)\n",
    "    await page.waitForSelector('#port-calls', {'timeout': 50000})  # 等待ID为port-calls的元素加载\n",
    "\n",
    "    # 获取ID为port-calls的元素的HTML内容\n",
    "    element = await page.querySelector('#port-calls')\n",
    "    content = await page.evaluate('(element) => element.innerHTML', element)\n",
    "\n",
    "    await browser.close()\n",
    "    return content\n",
    "\n",
    "\n",
    "\n",
    "async def main():\n",
    "    data = []\n",
    "    for key, url in processingData.items():\n",
    "        html_content = await scrape(url)\n",
    "        \n",
    "        # 使用BeautifulSoup解析HTML\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # 找到所有相关的div元素\n",
    "        divs = soup.find_all('div', class_='_1hgmG')\n",
    "\n",
    "        # 解析数据\n",
    "        for div in divs:\n",
    "            location = div.find_previous_sibling('a').text.strip()\n",
    "            arrival = div.find('div', class_='_1GQkK').text.strip()\n",
    "            data.append({'location': location, 'Arrival': arrival})\n",
    "\n",
    "    # 创建DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# 在Jupyter notebook中运行异步代码\n",
    "df = await main()\n",
    "\n",
    "# 打印DataFrame的内容\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div><a href=\"/ports/AUBTB002\" class=\"flx _rLk t5UW5\"><span class=\"flag-icon _jFl3\" title=\"Australia\" style=\"background-image:url(https://static.vesselfinder.net/images/flags/4x3/au.svg)\"></span>Botany Bay, Australia</a><div class=\"flx _1hgmG\"><div class=\"_211eJ\"><div class=\"_2nufK\">Arrival (UTC)</div><div class=\"_1GQkK\">Mar 20, 09:48</div></div><div class=\"_211eJ\"><div class=\"_2nufK\">Departure (UTC)</div><div class=\"_1GQkK\">-</div></div><div class=\"_2q7TN\"><div class=\"_2nufK\">In Port</div><div class=\"_1GQkK\">-</div></div></div></div><div><a href=\"/ports/CNSZX001\" class=\"flx _rLk t5UW5\"><span class=\"flag-icon _jFl3\" title=\"China\" style=\"background-image:url(https://static.vesselfinder.net/images/flags/4x3/cn.svg)\"></span>Shenzhen, China</a><div class=\"flx _1hgmG\"><div class=\"_211eJ\"><div class=\"_2nufK\">Arrival (UTC)</div><div class=\"_1GQkK\">Mar 6, 21:03</div></div><div class=\"_211eJ\"><div class=\"_2nufK\">Departure (UTC)</div><div class=\"_1GQkK\">Mar 7, 09:14</div></div><div class=\"_2q7TN\"><div class=\"_2nufK\">In Port</div><div class=\"_1GQkK\">12h 11m</div></div></div></div><div><a href=\"/ports/CNNSA001\" class=\"flx _rLk t5UW5\"><span class=\"flag-icon _jFl3\" title=\"China\" style=\"background-image:url(https://static.vesselfinder.net/images/flags/4x3/cn.svg)\"></span>Nansha, China</a><div class=\"flx _1hgmG\"><div class=\"_211eJ\"><div class=\"_2nufK\">Arrival (UTC)</div><div class=\"_1GQkK\">Mar 5, 21:15</div></div><div class=\"_211eJ\"><div class=\"_2nufK\">Departure (UTC)</div><div class=\"_1GQkK\">Mar 6, 10:06</div></div><div class=\"_2q7TN\"><div class=\"_2nufK\">In Port</div><div class=\"_1GQkK\">12h 50m</div></div></div></div><div><a href=\"/ports/CNSHG002\" class=\"flx _rLk t5UW5\"><span class=\"flag-icon _jFl3\" title=\"China\" style=\"background-image:url(https://static.vesselfinder.net/images/flags/4x3/cn.svg)\"></span>Shanghai, China</a><div class=\"flx _1hgmG\"><div class=\"_211eJ\"><div class=\"_2nufK\">Arrival (UTC)</div><div class=\"_1GQkK\">Mar 2, 18:57</div></div><div class=\"_211eJ\"><div class=\"_2nufK\">Departure (UTC)</div><div class=\"_1GQkK\">Mar 3, 08:04</div></div><div class=\"_2q7TN\"><div class=\"_2nufK\">In Port</div><div class=\"_1GQkK\">13h 6m</div></div></div></div><div><a href=\"/ports/CNQDG002\" class=\"flx _rLk t5UW5\"><span class=\"flag-icon _jFl3\" title=\"China\" style=\"background-image:url(https://static.vesselfinder.net/images/flags/4x3/cn.svg)\"></span>Qingdao, China</a><div class=\"flx _1hgmG\"><div class=\"_211eJ\"><div class=\"_2nufK\">Arrival (UTC)</div><div class=\"_1GQkK\">Feb 29, 10:28</div></div><div class=\"_211eJ\"><div class=\"_2nufK\">Departure (UTC)</div><div class=\"_1GQkK\">Mar 1, 13:07</div></div><div class=\"_2q7TN\"><div class=\"_2nufK\">In Port</div><div class=\"_1GQkK\">1d 2h</div></div></div></div>\n"
     ]
    }
   ],
   "source": [
    "# import asyncio\n",
    "# import nest_asyncio\n",
    "# from pyppeteer import launch\n",
    "\n",
    "# nest_asyncio.apply()  # 应用nest_asyncio\n",
    "\n",
    "# async def scrape(url):\n",
    "#     browser = await launch(headless=True, args=['--no-sandbox'])\n",
    "#     page = await browser.newPage()\n",
    "#     await page.setUserAgent('My User Agent')\n",
    "#     await page.goto(url)\n",
    "#     await page.waitForSelector('#port-calls', {'timeout': 50000})  # 等待ID为port-calls的元素加载\n",
    "\n",
    "#     # 获取ID为port-calls的元素的HTML内容\n",
    "#     element = await page.querySelector('#port-calls')\n",
    "#     content = await page.evaluate('(element) => element.innerHTML', element)\n",
    "\n",
    "#     await browser.close()\n",
    "#     return content\n",
    "\n",
    "# url = 'https://www.vesselfinder.com/vessels/details/9267651'\n",
    "\n",
    "# # 在Jupyter notebook中运行异步代码\n",
    "# div_content = await scrape(url)\n",
    "\n",
    "# # 打印div中的内容\n",
    "# print(div_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               location1       Arrival1        location2      Arrival2  \\\n",
      "0  Botany Bay, Australia  Mar 20, 09:48  Shenzhen, China  Mar 6, 21:03   \n",
      "\n",
      "       location3      Arrival3        location4      Arrival4       location5  \\\n",
      "0  Nansha, China  Mar 5, 21:15  Shanghai, China  Mar 2, 18:57  Qingdao, China   \n",
      "\n",
      "        Arrival5  \n",
      "0  Feb 29, 10:28  \n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# # 假定 html_content 包含了你的HTML内容\n",
    "# html_content = div_content\n",
    "\n",
    "# # 使用BeautifulSoup解析HTML\n",
    "# soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# # 找到所有相关的div元素\n",
    "# divs = soup.find_all('div', class_='_1hgmG')\n",
    "\n",
    "# # 解析数据\n",
    "# data = []\n",
    "# for div in divs:\n",
    "#     # 获取地点和到达时间\n",
    "#     location = div.find_previous_sibling('a').text.strip()\n",
    "#     arrival = div.find('div', class_='_1GQkK').text.strip()\n",
    "#     data.append({'location': location, 'Arrival': arrival})\n",
    "\n",
    "# # 创建DataFrame\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # 重塑DataFrame以使每个位置和到达成为单独的列\n",
    "# reshaped_df = pd.DataFrame()\n",
    "# for i, row in enumerate(df.itertuples(), 1):\n",
    "#     reshaped_df[f'location{i}'] = [row.location]\n",
    "#     reshaped_df[f'Arrival{i}'] = [row.Arrival]\n",
    "\n",
    "# print(reshaped_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalPorjectwithoutAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
